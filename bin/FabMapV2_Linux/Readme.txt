===================
    LICENCE
===================

This software is licensed for non-commercial use.
You may freely use or redistribute this software subject to the above condition.
For a commercial licence, please contact the authors via http://www.robots.ox.ac.uk/~mobile/

The software contains a redistribution of the SURF library, which is also licence for non-commercial use.
See details at http://www.vision.ee.ethz.ch/~surf/download.html

See Licence.txt for details.

===================
  Quick Start
===================

1) Install ImageMagick from http://www.imagemagick.org
 (On most Linux systems this should already be installed. You can check by typing convert.)


Now you can generate some loop closures on
the test dataset located in  Resources/Sample_Data/Images

2)  Open a terminal in the bin directory and call
  
   a)  ./WordMaker WordMaker_BatchConfig.moos
 
	This converts images to bag-of-words format.
	If you look in Sample_Data you should now see three new items:

	Surf			        - A directory containing the Surf features for each image.
	Words_VocabName 	    - A directory containing the bag-of-words for each image (with respect to the named vocabulary)
	Scenes_VocabName.oxs	- An index file listing image names, and the corresponding bag-of-words.
				  This index file is the input to FabMap


  Now run

   b) ./FabMapV2 FabMapV2_BatchConfig.moos
	
	This runs the FabMap algorithm (version 2) based on inverted file implementation.
	The input is .oxs index file generated by WordMaker. Have a look in the config file (FabMap_BatchConfig.moos).
	
	Images are processed in the order in which they appear in the index file (corresponding to alphabetic sort by filename).
	For each image, we calculate the probability that it came from the same place as each of the previous images.
	
	The output will appear in the Results directory.
	The output is a matrix, the n-th entry of which corresponds to the pdf over previously seen places due to the n-th image.
	The final entry in each pdf is special - it is the probability that the query image came from a NEW place, not seen before.

	The default output format is plain text (extension .tmd).
	There is also an option to output Matlab matrices. Have a look in the configuration file FabMap_BatchConfig.moos
	
	A nice way to visualize the pdf in Matlab is to call imagesc(psame).
	Entry (i,j) in the matrix is the probability that image i came from the same place as image j.
	Loop closures should be visible as bright off-diagonal lines.
	Note that the main diagonal is special. Entry (i,i) in the matrix is the probability that image i came from a NEW place, not seen before.
	Therefore, high probability entries on the main diagonal indicate the detection of new places.
 
	

3) To run on your own data

Have a look in the configuration files.

	WordMaker_BatchConfig.moos
	and 
	FabMapV2_BatchConfig.moos

To run on your own data, just change the paths to point to your images.

We're using ImageMagick for loading images, so input can be almost any format you want. 
However, we find that compressed formats like jpeg or png typically add 200ms overhead compared to simple formats like pgm.

===================
  SOME PITFALLS
===================
  
A) THE ORDER IN WHICH IMAGES ARE PROCESSED CORRESPONDS TO ALPHABETICAL SORT BY FILENAME.

   For processing sequences of images, make sure that this corresponds to the order in which they were collected.
   We suggest naming the images by timestamp or with sequential numbers as in Sample_Data/Images

   If you want to process the images in some other order, you can do this via the client-server version of the code.
   See Readme_ClientServer.txt


B) CONSECUTIVE FRAMES OF VIDEO ARE NOT SUITABLE INPUT FOR THE ALGORITHM.

   The method assumes that the places in the map are disjoint (that is, their views don't overlap). 
   Because the method only detects loop closure about 20-40% of the time, with video input many similar places 
   can accumulate in the map, which causes problems.

   For best results, video input should be filtered with some form of keyframe detection.
   Simply taking every 30th or 40th frame should be sufficient to get reasonable results. 
   For our experiments, we trigger image capture when the robot moves more than 1.5 meters or turns more than 60 degrees.
   The resulting data has some overlap in consecutive views, especially with a forward-looking camera, however a little overlap doesn't seem to cause problems.


===================
 References
===================

"Highly Scalable Appearance-Only SLAM Ð FAB-MAP 2.0", Mark Cummins and Paul Newman, Robotics Science and Systems 2009.
http://www.robots.ox.ac.uk/~mobile/Papers/FABMAP%202.0%20RSS%202009.pdf

======================================
Last updated by rohanp on 2010/7/30 
